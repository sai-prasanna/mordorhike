{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from powm.envs.mordor import MordorHike\n",
    "from dreamerv3 import embodied\n",
    "\n",
    "\n",
    "logdir = Path(\"/home/sai/Desktop/powm/experiments/train_dreamer\")\n",
    "config = embodied.Config.load(str(logdir / \"config.yaml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = np.load(logdir / \"episodes_50000.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the episodes into train, val, test as 80%, 10%, 10%\n",
    "train_episodes = episodes[\"episodes\"][:int(0.8 * len(episodes[\"episodes\"]))]\n",
    "val_episodes = episodes[\"episodes\"][int(0.8 * len(episodes[\"episodes\"])):int(0.9 * len(episodes[\"episodes\"]))]\n",
    "test_episodes = episodes[\"episodes\"][int(0.9 * len(episodes[\"episodes\"])):]\n",
    "collapse_angle_prediction = config.task == \"gymnasium_mordor-hike-easy-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any difficulty is fine as we use it primarily for visualization\n",
    "# But ideally we have to read the config and create the environment accordingly\n",
    "env = MordorHike.medium(render_mode=\"human\", estimate_belief=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(episodes):\n",
    "    episode_id = 0\n",
    "    X, Y = [], []\n",
    "    for episode_id in range(len(episodes)):\n",
    "        episode = episodes[episode_id]\n",
    "        episode[\"discrete_belief\"] = []\n",
    "        step = 0\n",
    "        for step in range(len(episode[\"belief\"])):\n",
    "            discretized_belief = env.discretize_belief(episode[\"belief\"][step])\n",
    "            # if collapse_angle_prediction:\n",
    "            #     discretized_belief = discretized_belief.sum(axis=-1, keepdims=True)\n",
    "            episode[\"discrete_belief\"].append(discretized_belief)\n",
    "            latent = episode[\"latents\"][step]\n",
    "            x = latent.reshape(-1)\n",
    "            y = discretized_belief.reshape(-1)\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "        episode[\"discrete_belief\"] = np.array(episode[\"discrete_belief\"])\n",
    "    return X, Y\n",
    "\n",
    "train_X, train_Y = make_dataset(train_episodes)\n",
    "val_X, val_Y = make_dataset(val_episodes)\n",
    "test_X, test_Y = make_dataset(test_episodes)\n",
    "belief_shape = test_episodes[0][\"discrete_belief\"][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert to tensors\n",
    "train_X = torch.FloatTensor(train_X)\n",
    "train_Y = torch.FloatTensor(train_Y)\n",
    "val_X = torch.FloatTensor(val_X)\n",
    "val_Y = torch.FloatTensor(val_Y)\n",
    "test_X = torch.FloatTensor(test_X)\n",
    "test_Y = torch.FloatTensor(test_Y)\n",
    "\n",
    "# Create model\n",
    "class BeliefPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(256, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128, output_dim),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Training setup\n",
    "model = BeliefPredictor(train_X.shape[1], train_Y.shape[1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Partial VAL loss 2.7790181636810303\n",
      "Epoch 0, Val Loss: 2.7790181636810303\n",
      "Epoch 1 Partial VAL loss 2.196852445602417\n",
      "Epoch 1, Val Loss: 2.196852445602417\n",
      "Epoch 2 Partial VAL loss 1.8721835613250732\n",
      "Epoch 2, Val Loss: 1.8721835613250732\n",
      "Epoch 3 Partial VAL loss 1.661014199256897\n",
      "Epoch 3, Val Loss: 1.661014199256897\n",
      "Epoch 4 Partial VAL loss 1.5571784973144531\n",
      "Epoch 4, Val Loss: 1.5571784973144531\n",
      "Epoch 5 Partial VAL loss 1.4677512645721436\n",
      "Epoch 5, Val Loss: 1.4677512645721436\n",
      "Epoch 6 Partial VAL loss 1.3808619976043701\n",
      "Epoch 6, Val Loss: 1.3808619976043701\n",
      "Epoch 7 Partial VAL loss 1.3130327463150024\n",
      "Epoch 7, Val Loss: 1.3130327463150024\n",
      "Epoch 8 Partial VAL loss 1.2879527807235718\n",
      "Epoch 8, Val Loss: 1.2879527807235718\n",
      "Epoch 9 Partial VAL loss 1.2596936225891113\n",
      "Epoch 9, Val Loss: 1.2596936225891113\n",
      "Epoch 10 Partial VAL loss 1.238360047340393\n",
      "Epoch 10, Val Loss: 1.238360047340393\n",
      "Epoch 11 Partial VAL loss 1.236532211303711\n",
      "Epoch 11, Val Loss: 1.236532211303711\n",
      "Epoch 12 Partial VAL loss 1.1931242942810059\n",
      "Epoch 12, Val Loss: 1.1931242942810059\n",
      "Epoch 13 Partial VAL loss 1.168786883354187\n",
      "Epoch 13, Val Loss: 1.168786883354187\n",
      "Epoch 14 Partial VAL loss 1.1995785236358643\n",
      "Epoch 14, Val Loss: 1.1995785236358643\n",
      "Epoch 15 Partial VAL loss 1.1349180936813354\n",
      "Epoch 15, Val Loss: 1.1349180936813354\n",
      "Epoch 16 Partial VAL loss 1.1342647075653076\n",
      "Epoch 16, Val Loss: 1.1342647075653076\n",
      "Epoch 17 Partial VAL loss 1.1095070838928223\n",
      "Epoch 17, Val Loss: 1.1095070838928223\n",
      "Epoch 18 Partial VAL loss 1.1312257051467896\n",
      "Epoch 18, Val Loss: 1.1312257051467896\n",
      "Epoch 19 Partial VAL loss 1.1414152383804321\n",
      "Epoch 19, Val Loss: 1.1414152383804321\n",
      "Epoch 20 Partial VAL loss 1.1188346147537231\n",
      "Epoch 20, Val Loss: 1.1188346147537231\n",
      "Epoch 21 Partial VAL loss 1.115187168121338\n",
      "Epoch 21, Val Loss: 1.115187168121338\n",
      "Epoch 22 Partial VAL loss 1.1109414100646973\n",
      "Epoch 22, Val Loss: 1.1109414100646973\n",
      "Epoch 23 Partial VAL loss 1.0880271196365356\n",
      "Epoch 23, Val Loss: 1.0880271196365356\n",
      "Epoch 24 Partial VAL loss 1.090246319770813\n",
      "Epoch 24, Val Loss: 1.090246319770813\n",
      "Epoch 25 Partial VAL loss 1.0798208713531494\n",
      "Epoch 25, Val Loss: 1.0798208713531494\n",
      "Epoch 26 Partial VAL loss 1.0851454734802246\n",
      "Epoch 26, Val Loss: 1.0851454734802246\n",
      "Epoch 27 Partial VAL loss 1.0753859281539917\n",
      "Epoch 27, Val Loss: 1.0753859281539917\n",
      "Epoch 28 Partial VAL loss 1.097946047782898\n",
      "Epoch 28, Val Loss: 1.097946047782898\n",
      "Epoch 29 Partial VAL loss 1.052781581878662\n",
      "Epoch 29, Val Loss: 1.052781581878662\n",
      "Epoch 30 Partial VAL loss 1.046113133430481\n",
      "Epoch 30, Val Loss: 1.046113133430481\n",
      "Epoch 31 Partial VAL loss 1.0476408004760742\n",
      "Epoch 31, Val Loss: 1.0476408004760742\n",
      "Epoch 32 Partial VAL loss 1.0606011152267456\n",
      "Epoch 32, Val Loss: 1.0606011152267456\n",
      "Epoch 33 Partial VAL loss 1.0493844747543335\n",
      "Epoch 33, Val Loss: 1.0493844747543335\n",
      "Epoch 34 Partial VAL loss 1.0565762519836426\n",
      "Epoch 34, Val Loss: 1.0565762519836426\n",
      "Epoch 35 Partial VAL loss 1.0335227251052856\n",
      "Epoch 35, Val Loss: 1.0335227251052856\n",
      "Epoch 36 Partial VAL loss 1.0449167490005493\n",
      "Epoch 36, Val Loss: 1.0449167490005493\n",
      "Epoch 37 Partial VAL loss 1.0602861642837524\n",
      "Epoch 37, Val Loss: 1.0602861642837524\n",
      "Epoch 38 Partial VAL loss 1.047631859779358\n",
      "Epoch 38, Val Loss: 1.047631859779358\n",
      "Epoch 39 Partial VAL loss 1.0228265523910522\n",
      "Epoch 39, Val Loss: 1.0228265523910522\n",
      "Epoch 40 Partial VAL loss 1.049952745437622\n",
      "Epoch 40, Val Loss: 1.049952745437622\n",
      "Epoch 41 Partial VAL loss 1.02985680103302\n",
      "Epoch 41, Val Loss: 1.02985680103302\n",
      "Epoch 42 Partial VAL loss 1.062595248222351\n",
      "Epoch 42, Val Loss: 1.062595248222351\n",
      "Epoch 43 Partial VAL loss 1.0607619285583496\n",
      "Epoch 43, Val Loss: 1.0607619285583496\n",
      "Epoch 44 Partial VAL loss 1.0371298789978027\n",
      "Epoch 44, Val Loss: 1.0371298789978027\n",
      "Epoch 45 Partial VAL loss 1.0497770309448242\n",
      "Epoch 45, Val Loss: 1.0497770309448242\n",
      "Epoch 46 Partial VAL loss 1.0316805839538574\n",
      "Epoch 46, Val Loss: 1.0316805839538574\n",
      "Epoch 47 Partial VAL loss 1.0583559274673462\n",
      "Epoch 47, Val Loss: 1.0583559274673462\n",
      "Epoch 48 Partial VAL loss 1.0720736980438232\n",
      "Epoch 48, Val Loss: 1.0720736980438232\n",
      "Epoch 49 Partial VAL loss 1.0354567766189575\n",
      "Epoch 49, Val Loss: 1.0354567766189575\n",
      "Epoch 50 Partial VAL loss 1.0558302402496338\n",
      "Epoch 50, Val Loss: 1.0558302402496338\n",
      "Epoch 51 Partial VAL loss 1.027999997138977\n",
      "Epoch 51, Val Loss: 1.027999997138977\n",
      "Epoch 52 Partial VAL loss 1.0783611536026\n",
      "Epoch 52, Val Loss: 1.0783611536026\n",
      "Epoch 53 Partial VAL loss 1.03255033493042\n",
      "Epoch 53, Val Loss: 1.03255033493042\n",
      "Epoch 54 Partial VAL loss 1.0257631540298462\n",
      "Epoch 54, Val Loss: 1.0257631540298462\n",
      "Epoch 55 Partial VAL loss 1.050743579864502\n",
      "Epoch 55, Val Loss: 1.050743579864502\n",
      "Epoch 56 Partial VAL loss 1.0395020246505737\n",
      "Epoch 56, Val Loss: 1.0395020246505737\n",
      "Epoch 57 Partial VAL loss 1.0350794792175293\n",
      "Epoch 57, Val Loss: 1.0350794792175293\n",
      "Epoch 58 Partial VAL loss 1.0694998502731323\n",
      "Epoch 58, Val Loss: 1.0694998502731323\n",
      "Epoch 59 Partial VAL loss 1.0502866506576538\n",
      "Epoch 59, Val Loss: 1.0502866506576538\n",
      "Epoch 60 Partial VAL loss 1.0651005506515503\n",
      "Epoch 60, Val Loss: 1.0651005506515503\n",
      "Epoch 61 Partial VAL loss 1.0365593433380127\n",
      "Epoch 61, Val Loss: 1.0365593433380127\n",
      "Epoch 62 Partial VAL loss 1.02720308303833\n",
      "Epoch 62, Val Loss: 1.02720308303833\n",
      "Epoch 63 Partial VAL loss 1.06658136844635\n",
      "Epoch 63, Val Loss: 1.06658136844635\n",
      "Epoch 64 Partial VAL loss 1.051914095878601\n",
      "Epoch 64, Val Loss: 1.051914095878601\n",
      "Epoch 65 Partial VAL loss 1.067155122756958\n",
      "Epoch 65, Val Loss: 1.067155122756958\n",
      "Epoch 66 Partial VAL loss 1.0536998510360718\n",
      "Epoch 66, Val Loss: 1.0536998510360718\n",
      "Epoch 67 Partial VAL loss 1.0627659559249878\n",
      "Epoch 67, Val Loss: 1.0627659559249878\n",
      "Epoch 68 Partial VAL loss 1.0579962730407715\n",
      "Epoch 68, Val Loss: 1.0579962730407715\n",
      "Epoch 69 Partial VAL loss 1.0441830158233643\n",
      "Epoch 69, Val Loss: 1.0441830158233643\n",
      "Epoch 70 Partial VAL loss 1.0506513118743896\n",
      "Epoch 70, Val Loss: 1.0506513118743896\n",
      "Epoch 71 Partial VAL loss 1.055685043334961\n",
      "Epoch 71, Val Loss: 1.055685043334961\n",
      "Epoch 72 Partial VAL loss 1.0401039123535156\n",
      "Epoch 72, Val Loss: 1.0401039123535156\n",
      "Epoch 73 Partial VAL loss 1.0531901121139526\n",
      "Epoch 73, Val Loss: 1.0531901121139526\n",
      "Epoch 74 Partial VAL loss 1.0502045154571533\n",
      "Epoch 74, Val Loss: 1.0502045154571533\n",
      "Epoch 75 Partial VAL loss 1.0499303340911865\n",
      "Epoch 75, Val Loss: 1.0499303340911865\n",
      "Epoch 76 Partial VAL loss 1.060433268547058\n",
      "Epoch 76, Val Loss: 1.060433268547058\n",
      "Epoch 77 Partial VAL loss 1.0681450366973877\n",
      "Epoch 77, Val Loss: 1.0681450366973877\n",
      "Epoch 78 Partial VAL loss 1.0508196353912354\n",
      "Epoch 78, Val Loss: 1.0508196353912354\n",
      "Epoch 79 Partial VAL loss 1.0326497554779053\n",
      "Epoch 79, Val Loss: 1.0326497554779053\n",
      "Epoch 80 Partial VAL loss 1.0595389604568481\n",
      "Epoch 80, Val Loss: 1.0595389604568481\n",
      "Epoch 81 Partial VAL loss 1.0439499616622925\n",
      "Epoch 81, Val Loss: 1.0439499616622925\n",
      "Epoch 82 Partial VAL loss 1.0710095167160034\n",
      "Epoch 82, Val Loss: 1.0710095167160034\n",
      "Epoch 83 Partial VAL loss 1.0727354288101196\n",
      "Epoch 83, Val Loss: 1.0727354288101196\n",
      "Epoch 84 Partial VAL loss 1.0542222261428833\n",
      "Epoch 84, Val Loss: 1.0542222261428833\n",
      "Epoch 85 Partial VAL loss 1.0509192943572998\n",
      "Epoch 85, Val Loss: 1.0509192943572998\n",
      "Epoch 86 Partial VAL loss 1.061510443687439\n",
      "Epoch 86, Val Loss: 1.061510443687439\n",
      "Epoch 87 Partial VAL loss 1.0560479164123535\n",
      "Epoch 87, Val Loss: 1.0560479164123535\n",
      "Epoch 88 Partial VAL loss 1.0405724048614502\n",
      "Epoch 88, Val Loss: 1.0405724048614502\n",
      "Epoch 89 Partial VAL loss 1.0798324346542358\n",
      "Epoch 89, Val Loss: 1.0798324346542358\n",
      "Epoch 90 Partial VAL loss 1.0911860466003418\n",
      "Epoch 90, Val Loss: 1.0911860466003418\n",
      "Epoch 91 Partial VAL loss 1.0773184299468994\n",
      "Epoch 91, Val Loss: 1.0773184299468994\n",
      "Epoch 92 Partial VAL loss 1.052481770515442\n",
      "Epoch 92, Val Loss: 1.052481770515442\n",
      "Epoch 93 Partial VAL loss 1.0629239082336426\n",
      "Epoch 93, Val Loss: 1.0629239082336426\n",
      "Epoch 94 Partial VAL loss 1.053006649017334\n",
      "Epoch 94, Val Loss: 1.053006649017334\n",
      "Epoch 95 Partial VAL loss 1.1018717288970947\n",
      "Epoch 95, Val Loss: 1.1018717288970947\n",
      "Epoch 96 Partial VAL loss 1.0651153326034546\n",
      "Epoch 96, Val Loss: 1.0651153326034546\n",
      "Epoch 97 Partial VAL loss 1.064070701599121\n",
      "Epoch 97, Val Loss: 1.064070701599121\n",
      "Epoch 98 Partial VAL loss 1.0732468366622925\n",
      "Epoch 98, Val Loss: 1.0732468366622925\n",
      "Epoch 99 Partial VAL loss 1.0680049657821655\n",
      "Epoch 99, Val Loss: 1.0680049657821655\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i, (batch_x, batch_y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch_x)\n",
    "        pred = pred.reshape(-1, *belief_shape)\n",
    "        batch_y = batch_y.reshape(-1, *belief_shape)\n",
    "        loss = criterion(pred.log(), batch_y)\n",
    "        for i in range(3):\n",
    "            loss += criterion(pred.sum(-i).log(), batch_y.sum(-i))\n",
    "        loss /= 4\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # validate on val set\n",
    "    val_pred = model(val_X)\n",
    "    val_loss = criterion(val_pred.log(), val_Y)\n",
    "    for i in range(3):\n",
    "        crit = criterion(val_pred.sum(-i).log(), val_Y.sum(-i))\n",
    "        val_loss += crit\n",
    "    val_loss /= 4\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = best_model(test_X)\n",
    "    #train_pred = best_model(train_X)\n",
    "    #val_pred = best_model(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 4)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belief_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PearsonRResult(statistic=-0.08525904803658363, pvalue=0.8031733359710731),\n",
       " 0.7235462069511414)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = best_model(test_X)\n",
    "    #train_pred = best_model(train_X)\n",
    "    #val_pred = best_model(val_X)\n",
    "overall_kldiv = criterion(test_pred.log(), test_Y).detach().numpy().item()\n",
    "episodic_scores = []\n",
    "episodic_kldiv = []\n",
    "idx = 0\n",
    "for episode in test_episodes:\n",
    "    \n",
    "    \n",
    "    end_idx = idx + len(episode[\"belief\"])\n",
    "    episode[\"predicted_belief\"] = test_pred[idx:end_idx].reshape(-1, *belief_shape).detach().numpy()\n",
    "    episode[\"discrete_belief\"] = test_Y[idx:end_idx].reshape(-1, *belief_shape).detach().numpy()\n",
    "    episodic_kl_div = criterion(test_pred[idx:end_idx].log(), test_Y[idx:end_idx]).detach().numpy().item()\n",
    "    episodic_score = episode[\"reward\"].sum()\n",
    "    episodic_scores.append(episodic_score)\n",
    "    episodic_kldiv.append(episodic_kl_div)\n",
    "    idx = end_idx\n",
    "# Pearson correlation coefficient between episodic scores and kldiv\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "episodic_correlation = pearsonr(episodic_scores, episodic_kldiv)\n",
    "episodic_correlation, overall_kldiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PearsonRResult(statistic=-0.12407415432447409, pvalue=0.7162579618873453),\n",
       " 0.7420356273651123)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodic_correlation, overall_kldiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 # plot the ground truth and prediction belief histogram side by side</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>fig, axs = plt.subplots(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, figsize=(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>))                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>time_idx = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">40</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 5 axs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].imshow(test_episodes[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>][<span style=\"color: #808000; text-decoration-color: #808000\">\"discrete_belief\"</span>][time_idx].sum(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>))                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>axs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].set_title(<span style=\"color: #808000; text-decoration-color: #808000\">\"Ground Truth\"</span>)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>axs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>].imshow(test_episodes[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>][<span style=\"color: #808000; text-decoration-color: #808000\">\"predicted_belief\"</span>][time_idx].sum(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>))                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>axs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>].set_title(<span style=\"color: #808000; text-decoration-color: #808000\">\"Prediction\"</span>)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndexError: </span>index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> is out of bounds for axis <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> with size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m5\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[2m# plot the ground truth and prediction belief histogram side by side\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mfig, axs = plt.subplots(\u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m, figsize=(\u001b[94m10\u001b[0m, \u001b[94m5\u001b[0m))                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mtime_idx = \u001b[94m40\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 5 axs[\u001b[94m0\u001b[0m].imshow(test_episodes[\u001b[94m4\u001b[0m][\u001b[33m\"\u001b[0m\u001b[33mdiscrete_belief\u001b[0m\u001b[33m\"\u001b[0m][time_idx].sum(-\u001b[94m1\u001b[0m))                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0maxs[\u001b[94m0\u001b[0m].set_title(\u001b[33m\"\u001b[0m\u001b[33mGround Truth\u001b[0m\u001b[33m\"\u001b[0m)                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0maxs[\u001b[94m1\u001b[0m].imshow(test_episodes[\u001b[94m4\u001b[0m][\u001b[33m\"\u001b[0m\u001b[33mpredicted_belief\u001b[0m\u001b[33m\"\u001b[0m][time_idx].sum(-\u001b[94m1\u001b[0m))                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0maxs[\u001b[94m1\u001b[0m].set_title(\u001b[33m\"\u001b[0m\u001b[33mPrediction\u001b[0m\u001b[33m\"\u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mIndexError: \u001b[0mindex \u001b[1;36m40\u001b[0m is out of bounds for axis \u001b[1;36m0\u001b[0m with size \u001b[1;36m40\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot the ground truth and prediction belief histogram side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "time_idx = 22\n",
    "episode = test_episodes[2]\n",
    "axs[0].imshow(test_episodes[4][\"discrete_belief\"][time_idx].sum(-1))\n",
    "axs[0].set_title(\"Ground Truth\")\n",
    "axs[1].imshow(test_episodes[4][\"predicted_belief\"][time_idx].sum(-1))\n",
    "axs[1].set_title(\"Prediction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def visualize_trajectory_step(env, episode, step_idx):\n",
    "    \"\"\"\n",
    "    Visualize a single step showing true and predicted belief distributions side by side\n",
    "    \"\"\"\n",
    "    # Get true and predicted belief grids\n",
    "    # We remove the last dimension as it is the angle dimension\n",
    "    true_grid = episode['discrete_belief'][step_idx].sum(-1)\n",
    "    pred_grid = episode['predicted_belief'][step_idx].sum(-1)\n",
    "\n",
    "    # Normalize grids to 0-255 range\n",
    "    true_grid = (((true_grid - true_grid.min()) / (true_grid.max() - true_grid.min())) * 255).astype(np.uint8)\n",
    "    pred_grid = (((pred_grid - pred_grid.min()) / (pred_grid.max() - pred_grid.min())) * 255).astype(np.uint8)\n",
    "    # Make y coordinates to be negative \n",
    "    true_grid = np.flip(true_grid, axis=1).T\n",
    "    pred_grid = np.flip(pred_grid, axis=1).T\n",
    "    \n",
    "    render_size = (256, 256)\n",
    "    # resize the grids to match the image size\n",
    "    true_grid = cv2.resize(true_grid, render_size)\n",
    "    pred_grid = cv2.resize(pred_grid, render_size)\n",
    "    \n",
    "    # Create two backgrounds\n",
    "    env.render_size = render_size  # Increased size for better visibility\n",
    "    true_img = env._create_background()\n",
    "    pred_img = true_img.copy()\n",
    "    h, w = true_img.shape[:2]\n",
    "    \n",
    "    # Convert belief grids to heatmaps\n",
    "    true_heatmap = cv2.applyColorMap(\n",
    "        (true_grid * 255).astype(np.uint8), \n",
    "        cv2.COLORMAP_JET\n",
    "    )\n",
    "    pred_heatmap = cv2.applyColorMap(\n",
    "        (pred_grid * 255).astype(np.uint8), \n",
    "        cv2.COLORMAP_JET\n",
    "    )\n",
    "    \n",
    "    # Blend heatmaps with background\n",
    "    alpha = 0.33\n",
    "    true_vis = cv2.addWeighted(true_img, 1-alpha, true_heatmap, alpha, 0)\n",
    "    pred_vis = cv2.addWeighted(pred_img, 1-alpha, pred_heatmap, alpha, 0)\n",
    "    \n",
    "    # Draw path and current position\n",
    "    path = episode['state'][:step_idx+1, :2]\n",
    "    current_state = episode['state'][step_idx]\n",
    "    path_pixels = env._world_to_pixel(path)\n",
    "    pos_pixel = env._world_to_pixel(current_state[:2])\n",
    "    \n",
    "    # Draw path\n",
    "    for img in [true_vis, pred_vis]:\n",
    "        cv2.polylines(img, [path_pixels.astype(np.int32)], False, (0, 0, 255), 2)\n",
    "        # Draw current position as red circle\n",
    "        cv2.circle(img, tuple(pos_pixel.astype(np.int32)), 5, (0, 0, 255), -1)\n",
    "    \n",
    "    # Stack images side by side\n",
    "    combined = np.hstack([true_vis, pred_vis])\n",
    "    \n",
    "    # Add labels and colorbar\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(combined, \"True Belief\", (10, 30), font, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(combined, \"Predicted Belief\", (w + 10, 30), font, 1, (255, 255, 255), 2)\n",
    "    \n",
    "    # Add colorbar\n",
    "    colorbar_h = 20\n",
    "    colorbar = np.linspace(0, 255, w).astype(np.uint8)\n",
    "    colorbar = cv2.applyColorMap(colorbar.reshape(1, -1), cv2.COLORMAP_JET)\n",
    "    colorbar = cv2.resize(colorbar, (w*2, colorbar_h))\n",
    "    \n",
    "    # Add min/max labels to colorbar\n",
    "    cv2.putText(colorbar, \"0.0\", (5, 15), font, 0.1, (255, 255, 255), 1)\n",
    "    cv2.putText(colorbar, \"1.0\", (w*2-30, 15), font, 0.1, (255, 255, 255), 1)\n",
    "    \n",
    "    # Combine visualization with colorbar\n",
    "    combined = np.vstack([combined, colorbar])\n",
    "    \n",
    "    return combined\n",
    "episode = test_episodes[7]\n",
    "frames = []\n",
    "for i in range(len(episode['state'])):\n",
    "    frame = visualize_trajectory_step(env, episode, step_idx=i)\n",
    "    frames.append(frame)\n",
    "    cv2.imshow('Trajectory Visualization', frame)\n",
    "    cv2.waitKey(100)  # 50ms delay between frames\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import imageio\n",
    "imageio.mimsave('trajectory.gif', frames, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
